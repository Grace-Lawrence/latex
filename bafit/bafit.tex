\documentclass[12pt,preprint]{aastex}

\usepackage{verbatim}
\usepackage{color}
\usepackage[normalem]{ulem} % for striking out with \sout
\usepackage{amsmath} % for boldsymbol
\input{newcommands.tex}

\def\eps@scaling{1.0}% 

\newcommand{\sn}{$S/N$}
\newcommand{\Msn}{$(S/N)_{\textrm{matched}}$}
\newcommand{\Tsn}{$(S/N)_{\textrm{size}}$}
\newcommand{\fsn}{$(S/N)_{\textrm{flux}}$}

% stolen from the BA14 source
\newcommand{\vecg}{\mbox{\boldmath $g$}}
\newcommand{\vecD}{\mbox{\boldmath $D$}}
\newcommand{\vecQ}{\mbox{\boldmath $Q$}}
\newcommand{\matR}{\mbox{$\bf R$}}
\newcommand{\matC}{\mbox{$\bf C$}}
\newcommand{\bnabg}{ \boldsymbol{\nabla_g}}

\newcommand{\desreq}{$4\times 10^{-3}$}
\newcommand{\lsstreq}{$2\times 10^{-3}$}

\newcommand{\sersic}{S\'{e}rsic}

\newcommand{\lognormscatt}{30}

\slugcomment{Last revision \today}
\shortauthors{Sheldon}
\shorttitle{Bayesian Shear Estimation}

\begin{document}

\title{On Bayesian Shear Estimation}

\input{authors.tex}

\begin{abstract}

The Bayesian gravitational shear estimation algorithm developed by \cite{ba14}
can potentially be used to overcome noise bias and recover shear using very low
signal-to-noise ratio (\sn) galaxy images.  In that work the authors confirmed
the method is sufficiently unbiased for planned surveys ($\Delta g/g < 2 \times
10^{-3}$) in a simplified demonstration, but no test was performed on images.
Here I present a full implementation for fitting models to galaxy images,
including the effects of a point spread function (PSF) and pixelization.  I
tested the implementation using simulated galaxy images modeled as \sersic\
profiles with $n=1$ (exponential) and $n=4$ (\devauc), convolved with a PSF and
a flat pixel response function.  I used a round Gaussian model for the PSF to
avoid potential PSF-fitting errors. I simulated galaxies with mean {\it
observed, post-PSF} full-width at half maximum equal to approximately 1.2 times
that of the PSF, with log-normal scatter.  Similarly I generated fluxes with
log-normal scatter and a discrete set of mean fluxes tuned to produce various
optimal, matched signal-to-noise ratios in the range $10-1000$.  I applied a
constant shear to all images. I fit the simulated images to a model with the
true \sersic\ index to avoid modeling biases.   Under these controlled
conditions I recovered the input shear with fractional error $\Delta g/g < 2
\times 10^{-3}$ in all cases, confirming the method is sufficiently unbiased
for planned surveys.  This demonstration can be considered a
proof-of-principle, and encouragement for the implementation of a
model-independent approach.


\end{abstract}

\section{Introduction} \label{sec:intro}


Noise bias is one of the largest potential systematic effects in weak
gravitational shear measurements.  Noise bias is a multiplicative calibration
error, associated with some point estimators for shear in the presence
of noise, such as a maximum likelihood estimate or expectation value for the
ellipticity of a galaxy \citep{HirataAlign04,Refreg12,Melchior12,Miller13}.
Averaging these point estimators gives a biased estimate of the shear.  The
bias remains even when response terms are included, such as that introduced by
\cite{ksb95} and \cite{Bern02}.

Noise bias is not a small effect.  At flux signal-to-noise ratio (\sn) $\sim
10$, the effect can be $\sim1-10$\%, depending on the size of the galaxy
relative to the size of the point-spread-function (PSF).  This multiplicative
error is significantly larger than the requirements for planned and current
surveys, which are $\sim$0.2\% and $\sim$0.4\%, respectively
\citep{HutererSystematics06}.

A Bayesian approach to shear estimate was first proposed by \cite{Miller07}.
With that method, a point estimator for the shear is still used (the
expectation value of the galaxy ellipticity), but a response term is calculated
based on prior information of the true distribution of galaxy ellipticities and
the likelihood surface for a given galaxy.  A limitation of this method is that
no expression was derived for the mean shear from an ensemble of galaxies,
rather it was proposed to average the responses from individual galaxies.  This
pioneering approach performs well in comparison to many previous methods, but
does not meet the requirements for current and planned surveys \citep{ba14}.

Other approaches have been proposed. For example \cite{Zuntz13} propose to use
a point estimate from galaxy shapes and simply calibrate the answer using
simulated data.  A related idea has been proposed in schematic form by
\cite{Refregier13}, to use an iterative approach where the universe is
simulated and its parameters tuned, along with calibration parameters of the
measurement, to reproduce the observed results.  These methods are in principle
limited only by the accuracy of the simulations to represent the real universe.

A rigorous Bayesian formalism was developed by \cite{ba14}, hereafter BA14,
that has the potential to recover shear with good accuracy using even very low
\sn\ galaxy images.  Rather than relying on a point estimate for the shear,
they derived an expression for the mean shear estimated from an ensemble of
measurements, exploiting the fact that the posterior for the shear must
approach a Gaussian for a large ensemble.  They showed that the method is
sufficiently unbiased for current and planned surveys in a simple demonstration
with galaxy ellipticities only, but no implementation for use with galaxy
images was presented.

Here I present a full model-fitting implementation of the BA14 algorithm that
works on galaxy images, including the effects of the PSF and pixelization.  I
test the implementation using a simple set of image simulations of idealized
galaxy profiles, and show that under these controlled conditions the method
is sufficiently accurate for current and planned surveys.

Below I follow the notation of BA14, where a shear was represented by the
glyph \vecg.

\section{Algorithm} \label{sec:algo}

The full algorithm is presented in BA14 .  There are two important assumptions
underlying this approach (following the notation in BA14):

\begin{itemize}

    \item The shear is weak, $\vecg \ll 1$.

    \item The posterior distribution of the mean shear derived from a large
        ensemble of galaxy images is approximately Gaussian.

\end{itemize}

The assumption of small shear is true under many circumstances, but breaks down
along lines-of-sight near large over-densities, such as clusters of galaxies.
The second assumption follows from the central limit theorem: if the shear is
derived from a large enough ensemble of galaxy shapes, the posterior
necessarily approaches a Gaussian.

The likelihood or posterior distribution for a parameter derived from a single
galaxy will not generally be Gaussian except in the limit of high
signal-to-noise ratio (\sn). Even if such high \sn\ galaxies could be used,
galaxies have intrinsic shapes that are a large effective noise in a derived
average shear.  Some kind of averaging must be performed to extract a shear
from galaxy shapes.  Thus nothing substantial is ``lost'' by restricting shear
estimation to populations rather than individual galaxies.  

Under these assumptions, the authors of BA14 derived a second-order Taylor
expansion of the logarithm of the shear posterior about zero shear, consistent
with the Gaussian assumption:
\begin{equation} \label{eq:pexpand}
-\ln P(\vecg | \vecD) \approx {(\rm const)} - \ln P(\vecg) - \vecg \cdot \sum_i
    \frac{\vecQ_i}{P_i}
    + \frac{1}{2} \vecg \cdot \left[ \sum_i \left(\frac{\vecQ_i \vecQ^T_i}{P_i^2}
    - \frac{\matR_i}{P_i}\right) \right] \cdot \vecg,
\end{equation}
where \vecD\ is the data vector and \vecg\ is the two-component shear.  The
terms $P_i$, $\vecQ_i$, and $\matR_i$ are 
\begin{eqnarray} \label{eq:pqrdef}
P_i     & = & P(\vecD_i | \vecg=0) \nonumber \\
\vecQ_i & = & \left. \bnabg P(\vecD_i | \vecg)\right|_{\vecg=0} \\
\matR_i & = & \left. \bnabg \bnabg P(\vecD_i | \vecg)\right|_{\vecg=0}. \nonumber
\end{eqnarray}
$P$ is the bayesian ``prior'', and functionally corresponds to the true
distribution of all the relevant galaxy parameters.

Prior information is an important aspect of this method: it is the derivatives
of the un-lensed distribution of shapes with respect to shear that reflects the
affect of shear on the population; it represents how the ensemble of galaxy
shapes responds to a shear.  In other words, with knowledge of the true
population of shapes, and how that population transforms under shear, can one
infer the applied shear, even in the presence of noise.

To predict the observed distribution of shapes in general, the un-lensed
distribution of shapes must be mathematically sheared and compared to
observables.  However in the approximation given above, only derivatives near
$g=0$ are required and the mean shear $\bar{\vecg}$ and covariance matrix
$\matC_g$ can be found directly:
\begin{eqnarray}
\matC_g^{-1} & = & \sum_i \left(\frac{\vecQ_i \vecQ^T_i}{P_i^2} - \frac{\matR_i}{P_i}\right) \label{eq:cdef} \\
\bar{\vecg} & = &  \matC_g \sum_i \frac{\vecQ_i}{P_i}. \label{eq:shdef}
\end{eqnarray}

In practice the parameters of each galaxy are not precisely known. In that case
the derivatives in equation \ref{eq:pqrdef} can be averaged over the full
likelihood surface for each galaxy, taking care to use the prior
distribution given the shear.  These mean values can then be used in the
aggregates shown in Equation \ref{eq:shdef}.
%\begin{equation} \label{eq:marg}
%P_i     & = & P(\vecD_i | \vecg=0) \nonumber \\
%\vecQ_i & = & \left. \bnabg P(\vecD_i | \vecg)\right|_{\vecg=0} \\
%\matR_i & = & \left. \bnabg \bnabg P(\vecD_i | \vecg)\right|_{\vecg=0}. \nonumber
%\end{equation}

A conceptual outline for measurement of non-constant shear was also given by
BA14, as were third-order tweaks to the second-order perturbations.

A full implementation, fitting to pixelized galaxy images, was not attempted in
BA14.  The basic formalism was shown to work by generating shapes from
an analytic distribution, adding noise and shear, and recovering the underlying
shear using the second-order formula.

\section{Simulation} \label{sec:sim}

I simulated pairs of galaxy images with identical structural parameters, but
with position angles offset by 90 degrees, in order to cancel the intrinsic
shape noise.  This simulation strategy is known as a ``ring
test''\citep{Nakajima2007}. Using a ring test greatly reduces the number of
simulated images required to reach a desired precision in the recovered shear.

I used elliptical \sersic\ \citep{Sersic63} profiles to represent galaxies:
\begin{equation}
I(r) \varpropto \mathrm{exp} \left[ -\left( \frac{r}{r_0} \right)^{1/n} \right].
\end{equation}
I used two distinct values of the index: $n=1$ (exponential
disks), and $n=4$ (\devauc\ profiles).

I convolved the models with a simple simulated PSF, a single round Gaussian
with $\sigma = \sqrt{2}$ pixels.  I chose a round Gaussian PSF to minimize PSF
modeling errors and the additive bias potentially associated with a
non-circular PSF.  I then convolved the models with a uniform square pixel
response function.


For consistency, I chose the same un-lensed shape distribution
used in \cite{ba14}:
\begin{equation}
P_0(e^s)\propto \left[1-(e^s)^2\right]^2 \exp\left[-(e^s)^2/2\sigma_{\rm prior}^2\right],
\end{equation}
with $\sigma_{\rm prior}=0.3$. This distribution is sufficiently similar to the
distribution of true galaxy shapes to be useful in this test.  This
distribution also has the required property that it is twice differentiable.

I drew the other galaxy parameters from simple un-correlated distributions.  I
drew the size parameter from a log-normal distribution with \lognormscatt\%
scatter.  The mean of the size distribution was chosen such that in the average
galaxy images had {\it observed, post-PSF} full-width at half maximum (FWHM)
that was approximately 1.2 times that of the PSF.  Due to the log-normal
scatter, some galaxies were smaller and some larger.

I simulated different signal-to-noise ratios \Msn\ in the range $[10,1000]$.  I
accomplished this by drawing fluxes from the same underlying log-normal flux
distribution but adding more or less Gaussian noise as needed to produce the
desired mean \Msn.  The optimal, matched signal-to-noise ratio \Msn\ is defined
as
\begin{equation}
    (S/N)^2_{matched} = \frac{1}{\sigma^2_{sky}} \int I^2(x,y) dx dy
\end{equation}
This matched filter signal-to-noise can be shown to be the maximal possible
measure of the signal-to-noise ratio, and was used as the signal-to-noise ratio
definition for the GREAT08 shear measurement challenge \citep{BridleGREAT08}.

I drew the centroid from a Gaussian in each coordinate, with $\sigma$ of 0.1
pixels.  

By drawing sizes and fluxes from log-normal distributions I was attempting to
very roughly approximate a selection that might occur in real data, for example
binning galaxies by a robust flux measure such as a PSF flux.  Within a PSF
flux bin, the true distribution of flux would have a small tail to lower values
due to noise and a long tail to higher flux because galaxies can be larger than
the PSF, causing the PSF flux could be underestimated.

\section{Implementation} \label{sec:impl}

As described in \S \ref{sec:algo}, in the presence of noise the estimator
involves integrals of $P$, \vecQ\ and \matR\ over the full likelihood surface
for each galaxy.

Exploration of the likelihood surface in a high-dimensional space requires a
large number of model evaluations, so I found efficiency to be important.  As
an optimization, I approximated galaxy models as sums of Gaussians according
the to the fits in \citet{HoggGMix}.  I also fit the PSF using a Gaussian.  By
using Gaussians for both galaxy and PSF models I could perform fast analytic
convolutions of the galaxy model with the PSF; for gaussian convolutions, the
covariance matrices add.  This is a fast and simple alternative to convolutions
using Fourier transforms.

I used a fast, third order approximation to the exponential function for
evaluating the Gaussians in the galaxy models.  Even so, evaluation of the
exponential function was the computational bottleneck for the likelihood
evaluation.

I used a Markov Chain Monte Carlo (MCMC) to explore the likelihood surface.
Using a standard Metropolis-Hastings algorithm \citep{Metropolis53}  to fit for
galaxy parameters is challenging because galaxies have a wide variety of
best-fit model parameters and errors in those parameters, depending on the
noise level.  I did not find it straightforward to predict what the parameter
errors would be a priori, which made it difficult to choose a ``step size'' for
the MCMC chain.  This is one reason I used an affine invariant MCMC
\citet{GoodmanWeare10}.  An affine invariant MCMC is dynamically adapted to the
underlying distribution by comparing multiple ``walkers'' as they are moved
through the parameter space; it thus does not require tuning the step size.  I
used the implementation presented in \citet{Mackey13} for this work.

I applied priors to the non-shape parameters {\it during exploration} to
constrain the space and make exploration more efficient.

By using a fit to the observed, pixelized PSF, I accounted approximately for
the convolution by the pixels in the PSF model.  Thus the analytic convolution
of the PSF model with the galaxy model accounts for the all PSF and pixel
effects.  This worked well for the parameters I used, but for a less well
sampled PSF, even if it is Gaussian before pixelization, this approach will
break down. 

During fitting, I used prior distributions matched exactly to the true
distributions used in the simulation.  I used the correct \sersic\ index for
fitting in each case; i.e. when simulating exponential disks, I also fit an
exponential disk ($n=1$).  By choosing the true priors and model, I tested the
accuracy of the algorithm and likelihood sampling technique directly and
avoided confusion with other issues such as model bias or empirical prior
determination.

For the MCMC I used an affine parameter $a=2$, which gives an acceptance rate
of about 0.5. I used 80 ``walkers'' in the chain, with 400 initial steps for
burn-in followed by 200 additional steps for measuring expectation values.  I
found that increasing the number of steps beyond this amount did not improve
the results dramatically, but generally more steps did result in less bias.
This large number of steps may be excessive in many situations.

It may be worth while to further optimize the exploration of the likelihood
surface, both in terms of the number of steps used and the type of computing
resources used.  The problem is particularly amenable to use of graphics
processing units; a brief study showed an increase in speed of order 100 over
traditional processors.

I chose initial locations for the walkers to be centered on the maximum
likelihood solution found with a Levenberg-Marquardt method, with Guassian
scatter based on errors in that fit, truncated to positive for flux and size
and within -1 to 1 for shapes.  I also tried drawing the initial positions from
the priors.  Both methods gave consistent results, and were in turn consistent
with taking the starting locations centered on the true galaxy parameters.  For
the large number of burn-in steps that I used the result is rather insensitive
to the starting position.


As I will show in section \ref{sec:truebias}, the formulas in BA14 break down
at high shear.  However, it is beneficial to perform tests at high shear
because the number of simulated galaxies required to reach a specified
fractional noise in the measured shear will go roughly as the inverse square of
the shear.  For this reason I chose to expand about the {\it true} shear
instead of zero in Equations \ref{eq:pexpand} and \ref{eq:pqrdef}.  I performed
limited tests expanding about zero shear and shearing the images by only 0.01,
and got comparable results. 

\section{Results} \label{sec:results}

\subsection{Calibration Bias vs. True Shear} \label{sec:truebias}

Figure \ref{fig:nonoise} contains results for a zero-noise simulation.  The
fractional bias is shown as a function of true shear.  The bias is well fit by
a quadratic function of the true shear, shown in the red curve. This quadratic
error is expected for a second-order Taylor expansion.

\begin{figure}[t] \centering
 \centering 
 \includegraphics[scale=0.6]{figures/fracerr-vs-shear.eps}

 \caption{Fractional bias in the recovered shear $\Delta g/g = g/g_{true}-1$
     as a function of true shear,
     in a zero noise simulation.  The blue circles represent the recovered
     shear when using the posterior equations expanded to second order about
     zero shear.  The red diamonds represent expansion about the true shear.
     The solid curve represents the best-fitting quadratic function of the true
     shear $\Delta g/g \sim 1.9~g^2_{true}$.  The quadratic bias as a function of
     true shear indicates a break down of the second-order Taylor approximation
 presented in \cite{ba14}. The light and dark gray bands represent the
 requirements for current and planned surveys respectively.
 \label{fig:nonoise}}

\end{figure}

Because of this bias, I expanded the equations about the true shear rather than
zero shear, as explained in \S \ref{sec:impl}.

\subsection{Calibration Bias vs. Galaxy Signal-to-noise Ratio} \label{sec:snbias}

Figure \ref{fig:fracerr} contains the fractional error in the recovered shear
as a function of optimal, matched signal-to-noise ration \Msn, for the
simulated galaxies described in the previous sections.  In these controlled
conditions the estimator is unbiased at the $\sim 2\times 10^{-3}$ level.

\begin{figure}[p] \centering
 \centering 
 \includegraphics[scale=0.8]{figures/ngmix-fwhm1.2.eps}

 \caption{ Fractional bias in the recovered shear for the estimator presented
     in \cite{ba14}.  The bias is plotted as a function of the maximal, matched
     galaxy signal-to-noise ratio \Msn, for galaxies with exponential (\sersic\
     $n=1$) and \devauc\ profiles ($n=4$).  The simulated galaxy parameters
     were drawn from broad distributions in size, flux, and ellipticity.  The
     size distribution was log-normal with \lognormscatt\% scatter and mean
     such that the {\it observed, post-PSF} FWHM was approximately 1.2 times
     that of the PSF, mimicking the smallest faint galaxy that may pass a size
     as that used during star-galaxy separation.  The flux distribution was
     log-normal with \lognormscatt\% scatter, and mean chosen to produce the
     indicated signal-to-noise ratio.  The ellipticities were drawn from the
     simple distribution introduced in \cite{ba14}. Under these controlled
     conditions, this shear estimator meets the accuracy requirements for the
 Dark Energy Survey shown as the light gray band, and the Large Synoptic Survey
 Telescope survey, shown as the dark gray band.  \label{fig:fracerr}}

\end{figure}

The errors for the different values of \Msn\ appear to be correlated.  This is
most likely due to particulars of how the likelihood surface is explored,
and may be correctable by tuning the parameters of the affine-invariant
MCMC chain, such as number of walkers, burn-in, or post-burn-in steps.

\subsection{Comparison with Requirements for Current and Planned Surveys}
\label{sec:req}

In the figures above I showed gray bands representing the approximate
multiplicative bias requirements for current surveys such as the Dark Energy
Survey \citep[][DES]{DESWhitePaper} and the Hyper-Suprime-Cam survey
\citep[][HSC]{HSC12}, and planned surveys such as the Large Synoptic Survey
Telescope survey \citep[][LSST]{IvezicLSST08} and the Euclid Mission
\citep{Euclid2011}.  These requirements are based on
\citep{HutererSystematics06} assuming fiducial sky coverage and a degredation
in the dark energy equation of state parameter of less than 20\%.  The cut at
20\% is somewhat arbitrary, and was chosen to coincide very roughly with the
``official'' requirements for DES. The requirements are $\sim$\desreq\ for
current surveys and $\sim$\lsstreq\ for planned surveys.  These requirements
are met in all the cases that I tested.

The authors of \cite{ba14} noted that small and faint galaxies, for which the
ellipticity likelihood is broad, get little weight in the average shear
relative to larger and brighter galaxies.  This is an intrinsic feature of the
estimator, no additional weighting is needed.  Indeed I made no cuts on the
simulated galaxies used for this measurement, even though some had near zero
signal-to-noise ratio.  This is advantageous, as the shear measurement process
need  not necessarily introduce any additional selection effects.

In Figure \ref{fig:nonoise} I showed the multiplicative bias due to the
breakdown of the second-order Taylor expansion at higher shear.   This effect
is prohibitive for current surveys when the shear exceeds 0.05.  The authors of
BA14 suggested potentially using higher order information to tweak the second
order equations.  Perhaps a full mapping of the posterior of the shear could
also be performed, but this would require keeping a large amount of information
per galaxy.  Another possibility is iteration: if the shear field is predicted
directly using some functional form, as suggested by BA14 for non-constant
fields, one might expand about the predicted shear field in a second iteration
to refine the result.


\section{Summary} \label{sec:summary}

The model-fitting approach I presented here is useful as a proof-of-principle:
model-fitting is limited by the accuracy of the models to represent true
galaxies, and thus in real data additional errors be present, the so-called
``model bias''.  But if the shear can be recovered in a controlled simulation,
fitting known models, this is a strong encouragement for further development of
this method.

\cite{Kacprzak13} show that model bias may be on the order of baseline
requirements for current surveys, but potentially crippling for future surveys
with more stringent requirements. One potential solution is to fit models with
more freedom.  However, more complex models have more complex likelihood
surfaces, which requires more burn-in for an MCMC chain and more samples to
estimate the expectation values for the $P$, \vecQ\ and \matR\ parameters.

\cite{ba14} propose an alternative to the model-fitting technique based on
moments in Fourier space which makes no explicit parameterization of galaxy
light distributions.  An evaluation of this model free approach in the presence
of noise is worthy of study.

\section*{Acknowledgments}

ES is supported by DOE grant DE-AC02-98CH10886.

Thanks to Gary Bernstein, Bob Armstrong, Jim Bosch, Mike Jarvis and Robert
Lupton for many useful discussions; thanks to An$\check{\textrm{z}}$e Slosar for
suggesting I expand the equations about the true shear to reduce the number of
simulated images required for each test.  Thanks to the STAR, PHENIX and LBNE
experiments at BNL for use of spare cycles on their compute clusters, and to
the RACF staff at BNL for their continued, and disproportionately large support
of my work.


\bibliographystyle{apj}
% Bib database
\bibliography{apj-jour,astroref}

\end{document}

