Metacalibration is a recently introduced method to accurately measure weak
gravitational lensing shear using only the available imaging data, without
need for prior information about galaxy properties or calibration from
simulations.  The method involves distorting the image with a small known
shear, and calculating the response of a shear estimator to that applied
shear.  The method was shown to be accurate in moderate sized simulations with
relatively high signal-to-noise galaxy images, and without significant
selection effects.  In this work we introduce a formalism to correct for both
shear response and selection biases.  We also observe that, for relatively low
signal-to-noise images,  the correlated noise that arises during the
metacalibration process results in significant bias, for which we develop a
simple empirical correction.  To test this formalism, we created large image
simulations based on both parametric models and real galaxy images, including
tests with realistic point-spread-functions.  We varied the PSF ellipticity at
the five percent level.  In each simulation we applied a small, few percent
shear to the galaxy images.  We introduced additional challenges that arise in
real data, such as detection thresholds, stellar contamination, and missing
data.  We applied cuts on the measured galaxy properties to induce significant
selection effects.  Using our formalism, we recovered the input shear with an
accuracy better than a part in a thousand in all cases.


