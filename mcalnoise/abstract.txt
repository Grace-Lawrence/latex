Metacalibration is a recently introduced method to accurately measure
weak gravitational lensing shear using only the available imaging
data, without need for prior information about galaxy properties or
calibration from simulations.  The method involves distorting the
image with a small known shear, and calculating the response of a
shear estimator to that applied shear.  The method was shown to be
accurate in moderate sized simulations with relatively high
signal-to-noise galaxy images, and without significant selection
effects.  In this work we introduce a formalism to correct for both
shear response and selection biases.  We also observe that, for
relatively low signal-to-noise images,  the correlated noise that
arises during the metacalibration process results in significant bias,
for which we develop a simple empirical correction.  To test this
formalism,  we use large simulations based on both parametric models
and real galaxy images, including tests with realistic
point-spread-functions.  We introduce additional challenges that arise
in real data, such as detection thresholds, stellar contamination, and
missing data.  We apply cuts on the galaxy properties to induce
significant selection effects.  Using our formalism, we recover the
input shear with an accuracy better than a part in a thousand in all
cases.
