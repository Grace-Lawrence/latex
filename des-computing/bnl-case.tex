\documentclass[12pt]{article}
\usepackage{amsmath}
\title{DES Computing at BNL}
\author{Erin S. Sheldon\\
Brookhaven National Laboratory}
\date{}

\begin{document}
\maketitle

In this document we present the case for separate computing for DES lensing
pipeline work at Brookhaven National Laboratory (BNL).  Here we present a high
level view; technical details can be found in the full DES analysis computing
document.

The technology required to run the pipelines in production mode has been
developed ``in house'' at BNL:  
\begin{itemize}

    \item The processing framework was written by Sheldon. This system would
    have to be transferred, requiring significant time from Sheldon.

    \item In order to get the required data throughput, we use a distributed
    disk model built on the Hadoop Distributed File System (HDFS).  HDFS
    provides the throughput for image processing which we were not able to get
    using NFS servers.  It also provides high availabiltity; it can recover
    from machine loss transparently and without any system down time from the
    user standpoint.  We at BNL set this up and understand it. We would have to
    transfer the knowledge to another site.  This would require significant
    time from Sheldon and experts at BNL.
    
\end{itemize}

In production mode, we must have a tight relationship with those who maintain
the machines and software stack.  Although HDFS provides high availability, we
still need tight integration with the maintainers to deal with hardware
failures and software upgrades in order to work at maximum efficiency.  

The lensing pipeline will be run in ``production mode'': as data is gathered it
will be immediately processed through one or more lensing pipelines.  The data
will be re-processed dozens of times per year.  We need and expect to approach
100\% utilization of the computing resources.  For efficiency reasons, we do
not wish to fight for computing resources in a shared queue system with highly
inhomogeneous demands from a large number of users.  This is made more acute by
the fact that much of the lensing processing requires very high memory for each
job: we require that entire nodes be used for a given job, not just a single
core on a machine.  This type of job is much more difficult to schedule in an
inhomogeneous environment.

In summary, we require that the entire system matches well the requirements of
our application.   The technology and expertise already exists at BNL.  Neither
the technology nor expertise will will exist at another site, and much effort
will be required to bring it there.  This extra work and inefficiency will
introduce unneeded cost to the project and reduce time available to Sheldon and
others for scientific investigation.

\end{document}
